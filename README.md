## Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID




[![arXiv](https://img.shields.io/badge/arXiv-2503.17237-b31b1b.svg)](https://arxiv.org/pdf/2503.17237)
[![PyPI - Python Version](https://img.shields.io/badge/python-3.11-blue.svg?logo=python&logoColor=gold)](https://www.python.org/downloads/release/python-3110/)
[![Colab Notebook](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1x5T6woUdV6dD_T6qdYcKG04Q2iVVHGoD?usp=sharing)




This repository provides a strong baseline for multi-UAV tracking in thermal infrared videos by leveraging YOLOv12 and BoT-SORT with ReID. Our method provides a significant boost over the well-established YOLOv5 with the DeepSORT combination, offering a high-performance starting point for UAV swarm tracking.




ğŸ“¹ Preview:

[strong_baseline.webm](https://github.com/user-attachments/assets/702b3e80-fd3c-48f0-8032-a2a97563c19f)

ğŸ”— Full video available at: [Track 3](https://youtu.be/_IiUISzCeU8?si=19JnHdwS9GLoYdtL)

ğŸ” See also SOT inferences: [Track 1](https://youtu.be/HOwMRm1l124?si=ewlZ5wr1_CUDFWk_) and [Track 2](https://youtu.be/M7lSrqYkpEQ?si=EyVhfOPNRLPVzYI2)

ğŸŒ [CVPR2025](https://cvpr.thecvf.com/) | [Workshops](https://cvpr.thecvf.com/Conferences/2025/workshop-list) | [4th Anti-UAV Workshop](https://anti-uav.github.io/) | [Track-1](https://codalab.lisn.upsaclay.fr/competitions/21688) | [Track-2](https://codalab.lisn.upsaclay.fr/competitions/21690) | [Track-3](https://codalab.lisn.upsaclay.fr/competitions/21806)








## ğŸ—ï¸ News

Details soon








## ğŸš€ Quickstart: Installation and Demonstration


<details><summary>Installation</summary>

```bash
$ conda create -n yolov12_botsort python=3.11 -y
$ conda activate yolov12_botsort
$ git clone https://github.com/wish44165/YOLOv12-BoT-SORT-ReID.git
$ cd YOLOv12-BoT-SORT-ReID/BoT-SORT/yolov12/
$ wget https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu11torch2.2cxx11abiFALSE-cp311-cp311-linux_x86_64.whl
$ pip install -r requirements.txt
$ pip install -e .
$ cd ../
$ pip3 install torch torchvision torchaudio
$ pip3 install -r requirements.txt
$ python3 setup.py develop
$ pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'
$ pip3 install cython_bbox
$ pip3 install faiss-cpu
```
  
</details>


<details><summary>Folder Structure</summary>

```
YOLOv12-BoT-SORT-ReID/
â”œâ”€â”€ data/
â”‚Â Â  â””â”€â”€ demo/
â”‚Â Â   Â Â  â”œâ”€â”€ MOT/
â”‚Â Â   Â Â  â”‚Â Â  â”œâ”€â”€ Test_imgs/
â”‚Â Â   Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ MultiUAV-003/
â”‚Â Â   Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ MultiUAV-135/
â”‚Â Â   Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ MultiUAV-173/
â”‚Â Â   Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ MultiUAV-261/
â”‚Â Â   Â Â  â”‚Â Â  â””â”€â”€ TestLabels_FirstFrameOnly/
â”‚Â Â   Â Â  â”‚Â Â      â”œâ”€â”€ MultiUAV-003.txt
â”‚Â Â   Â Â  â”‚Â Â      â”œâ”€â”€ MultiUAV-135.txt
â”‚Â Â   Â Â  â”‚Â Â      â”œâ”€â”€ MultiUAV-173.txt
â”‚Â Â   Â Â  â”‚Â Â      â””â”€â”€ MultiUAV-261.txt
â”‚Â Â   Â Â  â””â”€â”€ SOT/
â”‚Â Â   Â Â      â”œâ”€â”€ Track1/
â”‚Â Â   Â Â      â”‚Â Â  â”œâ”€â”€ 20190926_111509_1_8/
â”‚Â Â   Â Â      â”‚Â Â  â”œâ”€â”€ 41_1/
â”‚Â Â   Â Â      â”‚Â Â  â”œâ”€â”€ new30_train-new/
â”‚Â Â   Â Â      â”‚Â Â  â””â”€â”€ wg2022_ir_050_split_01/
â”‚Â Â   Â Â      â””â”€â”€ Track2/
â”‚Â Â   Â Â          â”œâ”€â”€ 02_6319_0000-1499/
â”‚Â Â   Â Â          â”œâ”€â”€ 3700000000002_110743_1/
â”‚Â Â   Â Â          â”œâ”€â”€ DJI_0057_1/
â”‚Â Â   Â Â          â””â”€â”€ wg2022_ir_032_split_04/
â””â”€â”€ BoT-SORT/
```
  
</details>


<details><summary>Demonstration</summary>

```bash
$ cd BoT-SORT/

# Track 1
$ python3 tools/predict_track1.py --weights ./yolov12/weights/SOT_yolov12l.pt --source ../data/demo/SOT/Track1/ --img-size 640 --device "0" --conf-thres 0.01 --iou-thres 0.01 --track_high_thresh 0.1 --track_low_thresh 0.01 --fuse-score --agnostic-nms --min_box_area 4 --save_path_answer ./submit/track1/demo --hide-labels-name
# output: ./runs/detect/, ./submit/track1/demo/

# Track 2
$ python3 tools/predict_track2.py --weights ./yolov12/weights/SOT_yolov12l.pt --source ../data/demo/SOT/Track2/ --img-size 640 --device "0" --conf-thres 0.01 --iou-thres 0.01 --track_high_thresh 0.1 --track_low_thresh 0.01 --fuse-score --agnostic-nms --min_box_area 1 --save_path_answer ./submit/track2/demo --hide-labels-name
# output: ./runs/detect/, ./submit/track2/demo/

# Track 3
$ python3 tools/predict_track3.py --weights ./yolov12/weights/MOT_yolov12n.pt --source ../data/demo/MOT/ --img-size 1600 --device "0" --track_buffer 60 --save_path_answer ./submit/track3/demo --hide-labels-name
# output: ./runs/detect/, ./submit/track3/demo/

# Heatmap
$ cd yolov12/
$ python heatmap.py
# output: ./outputs/
```

</details>








## ğŸŒŸ Implementation Details


<details><summary>Hardware Information</summary>

### Laptop

- CPU: IntelÂ® Coreâ„¢ i7-12650H
- GPU: NVIDIA GeForce RTX 4050 Laptop GPU (6GB)
- RAM: 23734MiB

### HPC

- GPU: Spartan gpu-h100 (80GB), gpu-a100 (80GB)
  
</details>




### ğŸ–» Data Preparation


<details><summary>Officially Released</summary>

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15103888.svg)](https://doi.org/10.5281/zenodo.15103888)

```
4th_Anti-UAV_Challenge/
â”œâ”€â”€ baseline/
â”‚Â Â  â”œâ”€â”€ Baseline_code.zip
â”‚Â Â  â””â”€â”€ MultiUAV_Baseline_code_and_submissi.zip
â”œâ”€â”€ test/
â”‚Â Â  â”œâ”€â”€ MultiUAV_Test.zip
â”‚Â Â  â”œâ”€â”€ track1_test.zip
â”‚Â Â  â””â”€â”€ track2_test.zip
â””â”€â”€ train/
    â”œâ”€â”€ MultiUAV_Train.zip
    â””â”€â”€ train.zip
```
  
</details>


<details><summary>Strong Baseline</summary>

```
train/
â”œâ”€â”€ MOT/
â”‚Â Â  â””â”€â”€ AntiUAV_train_val.zip
â”œâ”€â”€ ReID/
â”‚Â Â  â”œâ”€â”€ MOT20_subset.zip
â”‚Â Â  â””â”€â”€ MOT20.zip
â””â”€â”€ SOT/
    â”œâ”€â”€ AntiUAV_train_val_test.zip
    â””â”€â”€ AntiUAV_train_val.zip
```

</details>


<details><summary>Enhancement</summary>

Details soon

</details>




### ğŸ“‚ Folder Structure

Details soon




### ğŸ”© Reproduction

Details soon








## âœ¨ Models

| Model                                                                                | size<br><sup>(pixels) | mAP<sup>val<br>50-95 | params<br><sup>(M) | FLOPs<br><sup>(G) |
| :----------------------------------------------------------------------------------- | :-------------------: | :-------------------:| :-----------------:| :---------------:|
| [SOT_yolov12l.pt](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/blob/main/BoT-SORT/yolov12/weights/SOT_yolov12l.pt) | 640                   | 67.2                 | 26.3                | 88.5               |
| [MOT_yolov12n.pt](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/blob/main/BoT-SORT/yolov12/weights/MOT_yolov12n.pt) | 1600                   | 77.7                 | 2.6                | 6.3              |








## ğŸ§© Integration

Details soon








## ğŸ“œ Citation

If you find this project helpful for your research or applications, we would appreciate it if you could give it a star and cite the paper.

```
@article{chen2025strong,
  title={Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID},
  author={Chen, Yu-Hsi},
  journal={arXiv preprint arXiv:2503.17237},
  year={2025}
}
```








## ğŸ™ Acknowledgments

A large portion of the code is adapted from [YOLOv12](https://github.com/sunsmarterjie/yolov12) and [BoT-SORT](https://github.com/NirAharon/BoT-SORT). Thanks for their excellent work!